{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.optim import Adam\n",
    "from torchvision.utils import make_grid\n",
    "import json\n",
    "from torchvision import transforms\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(L.LightningDataModule):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data_dir = config[\"data_dir\"]\n",
    "        self.batch_size = config[\"batch_size\"]\n",
    "        self.calculate_stats = config[\"calculate_stats\"]\n",
    "        self.default_mean = config[\"default_mean\"]\n",
    "        self.default_std = config[\"default_std\"]\n",
    "        self.num_workers = config[\"num_workers\"]\n",
    "        self.mean = self.default_mean\n",
    "        self.std = self.default_std\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # Download only once\n",
    "        MNIST(self.data_dir, train=True, download=True)\n",
    "        MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "        if self.calculate_stats:\n",
    "            # Initialize a dataset with transform just for calculating mean and std\n",
    "            mnist_for_calculation = MNIST(self.data_dir, train=True, download=False, transform=transforms.ToTensor())\n",
    "            self.mean, self.std = self.calculate_mean_std(mnist_for_calculation)\n",
    "\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Update transform with calculated or default mean and std\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((self.mean,), (self.std,))\n",
    "        ])\n",
    "\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == 'fit' or stage is None:\n",
    "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_mean_std(dataset):\n",
    "        loader = DataLoader(dataset, batch_size=1000, num_workers=1, shuffle=False)\n",
    "        mean = 0.0\n",
    "        std = 0.0\n",
    "        total_images = 0\n",
    "\n",
    "        for images, _ in loader:\n",
    "            batch_samples = images.size(0)\n",
    "            images = images.view(batch_samples, images.size(1), -1)\n",
    "            mean += images.mean(2).sum(0)\n",
    "            std += images.std(2).sum(0)\n",
    "            total_images += batch_samples\n",
    "\n",
    "        mean /= total_images\n",
    "        std /= total_images\n",
    "        return mean.item(), std.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(config['latent_dim'], 1024, 3, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(1024, 512, 3, 2, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, config['channels'], 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(config['channels'], 256, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1024, 3, 2, 0, bias=False),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(1024, 1, 3, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.model(img).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(L.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.automatic_optimization = False\n",
    "        self.generator = Generator(config)\n",
    "        self.discriminator = Discriminator(config)\n",
    "        self.validation_z = torch.randn(8, config['latent_dim'], 1, 1)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.generator(z)\n",
    "\n",
    "    def adversarial_loss(self, y_hat, y):\n",
    "        return F.binary_cross_entropy(y_hat, y)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs, _ = batch\n",
    "\n",
    "        # Sample noise\n",
    "        z = torch.randn(imgs.shape[0], self.config['latent_dim'], 1, 1)\n",
    "        z = z.type_as(imgs)\n",
    "\n",
    "        # Access optimizers\n",
    "        opt_g, opt_d = self.optimizers()        \n",
    "\n",
    "        # Train generator\n",
    "        self.generated_imgs = self(z)\n",
    "        g_loss = self.adversarial_loss(self.discriminator(self.generated_imgs), torch.ones((imgs.size(0), 1),device=self.device))\n",
    "        opt_g.zero_grad()\n",
    "        self.manual_backward(g_loss)\n",
    "        opt_g.step()\n",
    "        self.log('generator_loss', g_loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        # Train discriminator\n",
    "        real_loss = self.adversarial_loss(self.discriminator(imgs), torch.ones((imgs.size(0), 1),device=self.device))\n",
    "        fake_loss = self.adversarial_loss(self.discriminator(self(z).detach()), torch.zeros((imgs.size(0), 1),device=self.device))\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        opt_d.zero_grad()\n",
    "        self.manual_backward(d_loss)\n",
    "        opt_d.step()\n",
    "        self.log('discriminator_loss', d_loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        g_lr = self.config['g_lr']\n",
    "        d_lr = self.config['d_lr']\n",
    "        b1 = self.config['b1']\n",
    "        b2 = self.config['b2']\n",
    "\n",
    "        opt_g = Adam(self.generator.parameters(), lr=g_lr, betas=(b1, b2))\n",
    "        opt_d = Adam(self.discriminator.parameters(), lr=d_lr, betas=(b1, b2))\n",
    "        return opt_g, opt_d\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        z = torch.randn(8, self.config['latent_dim'], 1, 1)\n",
    "        z = z.type_as(batch[0])\n",
    "        generated_imgs = self(z)\n",
    "        return generated_imgs\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        z = torch.randn(8, self.config['latent_dim'], 1, 1)\n",
    "        z = z.type_as(next(self.generator.parameters()))\n",
    "        sample_imgs = self(z)\n",
    "        grid = make_grid(sample_imgs)\n",
    "        self.logger.experiment.add_image('generated_images', grid, self.current_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the configuration\n",
    "with open('../configs/config.json') as json_file:\n",
    "    config = json.load(json_file)\n",
    "\n",
    "# Initialize DataModule and Model using their respective configs\n",
    "dm = MNISTDataModule(config[\"dm\"])\n",
    "model = DCGAN(config[\"model\"])\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=config[\"trainer\"][\"max_epochs\"],\n",
    "    logger=L.pytorch.loggers.TensorBoardLogger(\n",
    "        config[\"trainer\"][\"log_dir\"], \n",
    "        name=config[\"trainer\"][\"logger_name\"]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# print(\"Generator Summary:\")\n",
    "# generator = model.generator\n",
    "# torchsummary.summary(generator, (config['model']['latent_dim'],1,1), device='cpu')\n",
    "\n",
    "# print(\"\\nDiscriminator Summary:\")\n",
    "# discriminator = model.discriminator\n",
    "# torchsummary.summary(discriminator, (config['model']['channels'], 28, 28), device='cpu')\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, dm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MNIST-GAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
